{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot\n",
    "from sqlglot import exp\n",
    "\n",
    "class SSCSCalculator:\n",
    "    def __init__(self):\n",
    "        # Configuration for weights\n",
    "        self.weights = {\n",
    "            exp.Join: 1,\n",
    "            exp.Where: 1,\n",
    "            exp.Group: 1,\n",
    "            exp.Having: 1,\n",
    "            exp.Order: 1,\n",
    "            exp.Case: 2,           # Branching logic = higher load\n",
    "            exp.Window: 2,         # Window functions are complex\n",
    "            exp.Connector: 1,      # AND / OR\n",
    "            exp.Subquery: 1        # Base penalty for existence of subquery\n",
    "        }\n",
    "        \n",
    "        # Configuration for Semantic Penalty\n",
    "        self.semantic_weight = 0.5  # Alpha in the formula\n",
    "        self.min_alias_length = 3\n",
    "        self.generic_aliases = {'temp', 'data', 't', 'x', 'val', 'obj', 'row'}\n",
    "\n",
    "    def calculate(self, sql: str):\n",
    "        \"\"\"\n",
    "        Parses SQL and returns the SSCS score along with a detailed breakdown.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            parsed = sqlglot.parse_one(sql)\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Parse Error: {e}\"}\n",
    "\n",
    "        # 1. Isolate CTEs and Main Query\n",
    "        ctes = []\n",
    "        main_query = parsed\n",
    "\n",
    "        # If there is a WITH clause, extract CTEs\n",
    "        if parsed.find(exp.CTE):\n",
    "            # We treat CTEs as independent \"functions\" for complexity\n",
    "            # Note: sqlglot stores CTEs in the 'with' arg of the main expression\n",
    "            ctes = parsed.find_all(exp.CTE)\n",
    "                # We analyze the main query as if the CTEs are just tables\n",
    "                # (The complexity of defining the CTE is handled separately)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        # 2. Calculate Structural Complexity (C_struct)\n",
    "        # Sum of CTE complexities + Main Query complexity\n",
    "        struct_score = 0\n",
    "        component_scores = []\n",
    "\n",
    "        # Analyze CTEs (Depth starts at 0 for each, promoting modularity)\n",
    "        for cte in ctes:\n",
    "            cte_score = self._compute_structural_score(cte.this, depth=0)\n",
    "            struct_score += cte_score\n",
    "            component_scores.append(f\"CTE '{cte.alias}': {cte_score}\")\n",
    "\n",
    "        # Analyze Main Query (Depth starts at 0)\n",
    "        # We explicitly exclude the WITH clause from traversal to avoid double counting\n",
    "        main_score = self._compute_structural_score(main_query, depth=0, exclude_node=exp.With)\n",
    "        struct_score += main_score\n",
    "        component_scores.append(f\"Main Query: {main_score}\")\n",
    "\n",
    "        # 3. Calculate Semantic Penalty (P_sem)\n",
    "        # We look at all aliases across the entire parsed tree globally\n",
    "        semantic_penalty, alias_stats = self._compute_semantic_penalty(parsed)\n",
    "\n",
    "        # 4. Final Formula: SSCS = C_struct * (1 + P_sem)\n",
    "        final_sscs = struct_score * (1 + semantic_penalty)\n",
    "\n",
    "        return {\n",
    "            \"sscs_score\": round(final_sscs, 2),\n",
    "            \"structural_score\": struct_score,\n",
    "            \"semantic_penalty\": round(semantic_penalty, 2),\n",
    "            \"breakdown\": component_scores,\n",
    "            \"alias_analysis\": alias_stats\n",
    "        }\n",
    "\n",
    "    def _compute_structural_score(self, node, depth, exclude_node=None):\n",
    "        \"\"\"\n",
    "        Recursive visitor to calculate complexity weights based on AST nodes.\n",
    "        Increases depth penalty for nested subqueries.\n",
    "        \"\"\"\n",
    "        score = 0\n",
    "        \n",
    "        # If this node is the one we want to exclude (e.g. the CTE definitions block), stop recursion\n",
    "        if exclude_node and isinstance(node, exclude_node):\n",
    "            return 0\n",
    "\n",
    "        # Apply Weight if node type is in our config\n",
    "        if type(node) in self.weights:\n",
    "            base_weight = self.weights[type(node)]\n",
    "            # Formula: Weight + Depth Penalty\n",
    "            # We add depth to the weight. Deeper logic is heavier.\n",
    "            score += base_weight + (0.5 * depth)\n",
    "\n",
    "        # Check for nesting triggers\n",
    "        # If we enter a Subquery (SELECT inside FROM/WHERE), increment depth\n",
    "        next_depth = depth\n",
    "        if isinstance(node, exp.Subquery):\n",
    "            next_depth += 1\n",
    "        \n",
    "        # Recursively visit children\n",
    "        # sqlglot's args.values() gives us lists of children or single children\n",
    "        for child_list in node.args.values():\n",
    "            if isinstance(child_list, list):\n",
    "                for child in child_list:\n",
    "                    if isinstance(child, exp.Expression):\n",
    "                        score += self._compute_structural_score(child, next_depth, exclude_node)\n",
    "            elif isinstance(child_list, exp.Expression):\n",
    "                score += self._compute_structural_score(child_list, next_depth, exclude_node)\n",
    "                \n",
    "        return score\n",
    "\n",
    "    def _compute_semantic_penalty(self, root_node):\n",
    "        \"\"\"\n",
    "        Scans the entire tree for aliases and calculates quality ratio.\n",
    "        \"\"\"\n",
    "        aliases = []\n",
    "        \n",
    "        # 1. Capture Explicit Aliases (SELECT x AS y)\n",
    "        for alias_node in root_node.find_all(exp.Alias):\n",
    "            aliases.append(alias_node.alias)\n",
    "            \n",
    "        # 2. Capture Table Aliases (FROM table AS t)\n",
    "        for table_node in root_node.find_all(exp.Table):\n",
    "            if table_node.alias:\n",
    "                aliases.append(table_node.alias)\n",
    "\n",
    "        if not aliases:\n",
    "            return 0.0, {\"total\": 0, \"bad\": []}\n",
    "\n",
    "        bad_aliases = []\n",
    "        for a in aliases:\n",
    "            is_bad = False\n",
    "            # Criteria 1: Too short\n",
    "            if len(a) < self.min_alias_length:\n",
    "                is_bad = True\n",
    "            # Criteria 2: Generic\n",
    "            elif a.lower() in self.generic_aliases:\n",
    "                is_bad = True\n",
    "            \n",
    "            if is_bad:\n",
    "                bad_aliases.append(a)\n",
    "\n",
    "        bad_ratio = len(bad_aliases) / len(aliases)\n",
    "        penalty = self.semantic_weight * bad_ratio\n",
    "        \n",
    "        return penalty, {\n",
    "            \"total\": len(aliases), \n",
    "            \"bad_count\": len(bad_aliases), \n",
    "            \"bad_examples\": bad_aliases[:5] # Show first 5\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cdcd791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSCS Score: 13.46\n",
      "------------------------------\n",
      "Structural Score: 9.5\n",
      "Semantic Penalty: 0.42 (Based on 5 bad aliases)\n",
      "\n",
      "Breakdown:\n",
      " - CTE 'revenue_cte': 2.0\n",
      " - CTE 'risky_users': 3.0\n",
      " - Main Query: 4.5\n",
      "\n",
      "Bad Aliases Found: ['c', 't1', 'c', 'o', 'r']\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage ---\n",
    "\n",
    "complex_sql = \"\"\"\n",
    "WITH revenue_cte AS (\n",
    "    SELECT \n",
    "        c.id, \n",
    "        sum(o.amount) as total_rev\n",
    "    FROM customers c\n",
    "    JOIN orders o ON c.id = o.customer_id\n",
    "    GROUP BY 1\n",
    "),\n",
    "risky_users AS (\n",
    "    SELECT \n",
    "        id \n",
    "    FROM revenue_cte r\n",
    "    WHERE r.total_rev > 10000 \n",
    "      AND (CASE WHEN r.total_rev > 50000 THEN 1 ELSE 0 END) = 1\n",
    ")\n",
    "SELECT \n",
    "    t1.id, \n",
    "    t1.total_rev\n",
    "FROM revenue_cte t1\n",
    "LEFT JOIN (\n",
    "    SELECT user_id, count(*) as c FROM logs GROUP BY 1\n",
    ") t2 ON t1.id = t2.user_id\n",
    "WHERE t1.id IN (SELECT id FROM risky_users)\n",
    "\"\"\"\n",
    "\n",
    "calc = SSCSCalculator()\n",
    "result = calc.calculate(complex_sql)\n",
    "\n",
    "print(f\"SSCS Score: {result['sscs_score']}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Structural Score: {result['structural_score']}\")\n",
    "print(f\"Semantic Penalty: {result['semantic_penalty']} (Based on {result['alias_analysis']['bad_count']} bad aliases)\")\n",
    "print(\"\\nBreakdown:\")\n",
    "for item in result['breakdown']:\n",
    "    print(f\" - {item}\")\n",
    "print(\"\\nBad Aliases Found:\", result['alias_analysis']['bad_examples'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f6222c",
   "metadata": {},
   "source": [
    "## Do it again but calculate SSCS for CTEs instead of just structural score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4e1fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot\n",
    "from sqlglot import exp\n",
    "\n",
    "class SSCSCalculator:\n",
    "    def __init__(self):\n",
    "        # Configuration for weights\n",
    "        self.weights = {\n",
    "            exp.Join: 1,\n",
    "            exp.Where: 1,\n",
    "            exp.Group: 1,\n",
    "            exp.Having: 1,\n",
    "            exp.Order: 1,\n",
    "            exp.Case: 2,           # Branching logic = higher load\n",
    "            exp.Window: 2,         # Window functions are complex\n",
    "            exp.Connector: 1,      # AND / OR\n",
    "            exp.Subquery: 1        # Base penalty for existence of subquery\n",
    "        }\n",
    "        \n",
    "        # Configuration for Semantic Penalty\n",
    "        self.semantic_weight = 0.5  # Max penalty (50% increase)\n",
    "        self.min_alias_length = 3\n",
    "        self.generic_aliases = {'temp', 'data', 't', 'x', 'val', 'obj', 'row', 'a', 'b', 'c', 't1', 't2'}\n",
    "\n",
    "    def calculate(self, sql: str):\n",
    "        try:\n",
    "            parsed = sqlglot.parse_one(sql)\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Parse Error: {e}\"}\n",
    "\n",
    "        components = []\n",
    "\n",
    "        # 1. Analyze CTEs individually\n",
    "        # We find all CTE definitions. \n",
    "        # Note: We assume standard CTEs. Recursive CTEs are treated as normal CTEs here.\n",
    "        for cte in parsed.find_all(exp.CTE):\n",
    "            # The 'this' of a CTE is the query inside it (the definition)\n",
    "            cte_name = cte.alias\n",
    "            cte_expression = cte.this\n",
    "            \n",
    "            comp_result = self._analyze_component(cte_expression, name=f\"CTE: {cte_name}\")\n",
    "            components.append(comp_result)\n",
    "\n",
    "        # 2. Analyze Main Query\n",
    "        # We need to analyze the main query BUT exclude the WITH clause itself \n",
    "        # so we don't double-count the CTEs inside the Main Query score.\n",
    "        # We create a deep copy or just traverse carefully. \n",
    "        # Easier approach: Transform the tree to remove the WITH clause temporarily for analysis.\n",
    "        main_query_node = parsed.copy()\n",
    "        if main_query_node.find(exp.With):\n",
    "             main_query_node.find(exp.With).pop()\n",
    "             \n",
    "        comp_result = self._analyze_component(main_query_node, name=\"Main SELECT\")\n",
    "        components.append(comp_result)\n",
    "\n",
    "        return {\n",
    "            \"components\": components,\n",
    "            \"max_sscs\": max(c['sscs'] for c in components) if components else 0\n",
    "        }\n",
    "\n",
    "    def _analyze_component(self, node, name):\n",
    "        \"\"\"\n",
    "        Calculates SSCS for a single isolated component (CTE or Main Query).\n",
    "        \"\"\"\n",
    "        # A. Structural Score\n",
    "        struct_score = self._compute_structural_score(node, depth=0)\n",
    "        \n",
    "        # B. Semantic Penalty (Local to this component)\n",
    "        semantic_penalty, alias_details = self._compute_semantic_penalty(node)\n",
    "        \n",
    "        # C. Final Calculation\n",
    "        sscs = struct_score * (1 + semantic_penalty)\n",
    "        \n",
    "        return {\n",
    "            \"name\": name,\n",
    "            \"sscs\": round(sscs, 2),\n",
    "            \"structural\": struct_score,\n",
    "            \"semantic_penalty\": round(semantic_penalty, 2),\n",
    "            \"bad_aliases\": alias_details['bad_examples']\n",
    "        }\n",
    "\n",
    "    def _compute_structural_score(self, node, depth):\n",
    "        score = 0\n",
    "        \n",
    "        # Apply Weight\n",
    "        if type(node) in self.weights:\n",
    "            base_weight = self.weights[type(node)]\n",
    "            score += base_weight + (0.5 * depth)\n",
    "\n",
    "        # Increment depth ONLY for Subqueries (nested SELECTs), not for just any child\n",
    "        next_depth = depth\n",
    "        if isinstance(node, exp.Subquery):\n",
    "            next_depth += 1\n",
    "        \n",
    "        # Recurse\n",
    "        for child_list in node.args.values():\n",
    "            if isinstance(child_list, list):\n",
    "                for child in child_list:\n",
    "                    if isinstance(child, exp.Expression):\n",
    "                        score += self._compute_structural_score(child, next_depth)\n",
    "            elif isinstance(child_list, exp.Expression):\n",
    "                score += self._compute_structural_score(child_list, next_depth)\n",
    "                \n",
    "        return score\n",
    "\n",
    "    def _compute_semantic_penalty(self, root_node):\n",
    "        aliases = []\n",
    "        \n",
    "        # 1. Capture Explicit Aliases (SELECT x AS y)\n",
    "        for alias_node in root_node.find_all(exp.Alias):\n",
    "            aliases.append(alias_node.alias)\n",
    "            \n",
    "        # 2. Capture Table Aliases (FROM table AS t)\n",
    "        for table_node in root_node.find_all(exp.Table):\n",
    "            if table_node.alias:\n",
    "                aliases.append(table_node.alias)\n",
    "\n",
    "        if not aliases:\n",
    "            return 0.0, {\"bad_examples\": []}\n",
    "\n",
    "        bad_aliases = []\n",
    "        for a in aliases:\n",
    "            if len(a) < self.min_alias_length or a.lower() in self.generic_aliases:\n",
    "                bad_aliases.append(a)\n",
    "\n",
    "        bad_ratio = len(bad_aliases) / len(aliases)\n",
    "        penalty = self.semantic_weight * bad_ratio\n",
    "        \n",
    "        return penalty, {\n",
    "            \"bad_examples\": bad_aliases[:5]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ddc82bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CTE: revenue_cte | SSCS: 2.67 (Struct: 2.0, Pen: 0.33)\n",
      "  Bad Aliases: ['c', 'o']\n",
      "CTE: risky_users | SSCS: 4.5 (Struct: 3.0, Pen: 0.5)\n",
      "  Bad Aliases: ['r']\n",
      "Main SELECT | SSCS: 6.75 (Struct: 4.5, Pen: 0.5)\n",
      "  Bad Aliases: ['c', 't1']\n"
     ]
    }
   ],
   "source": [
    "# --- Test ---\n",
    "complex_sql = \"\"\"\n",
    "WITH revenue_cte AS (\n",
    "    SELECT \n",
    "        c.id, \n",
    "        sum(o.amount) as total_rev\n",
    "    FROM customers c\n",
    "    JOIN orders o ON c.id = o.customer_id\n",
    "    GROUP BY 1\n",
    "),\n",
    "risky_users AS (\n",
    "    SELECT \n",
    "        id \n",
    "    FROM revenue_cte r\n",
    "    WHERE r.total_rev > 10000 \n",
    "      AND (CASE WHEN r.total_rev > 50000 THEN 1 ELSE 0 END) = 1\n",
    ")\n",
    "SELECT \n",
    "    t1.id, \n",
    "    t1.total_rev\n",
    "FROM revenue_cte t1\n",
    "LEFT JOIN (\n",
    "    SELECT user_id, count(*) as c FROM logs GROUP BY 1\n",
    ") t2 ON t1.id = t2.user_id\n",
    "WHERE t1.id IN (SELECT id FROM risky_users)\n",
    "\"\"\"\n",
    "\n",
    "calc = SSCSCalculator()\n",
    "res = calc.calculate(complex_sql)\n",
    "\n",
    "for comp in res['components']:\n",
    "    print(f\"{comp['name']} | SSCS: {comp['sscs']} (Struct: {comp['structural']}, Pen: {comp['semantic_penalty']})\")\n",
    "    if comp['bad_aliases']:\n",
    "        print(f\"  Bad Aliases: {comp['bad_aliases']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
